{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will reproduce the results of experiments with merging Named Entities based signal with content similarity measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply different content similarity measures to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to reproduce the results of the experiemnt thoroughly strat from this section, calculate standr metrocs and Named Entities based metric first.\n",
    "If you don't want to recalculate it use 'SGDD-TST_with_metrics.csv' file where all the scores are already present. In thos case you may go to the Section 'Merge Named Entities based metric with regular metrics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/SGDD-TST.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INPUT:text_first</th>\n",
       "      <th>INPUT:text_second</th>\n",
       "      <th>OUTPUT:result</th>\n",
       "      <th>CONFIDENCE:result</th>\n",
       "      <th>vote_type</th>\n",
       "      <th>vote_different</th>\n",
       "      <th>vote_some_details_lost</th>\n",
       "      <th>vote_OK</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4th of March, 4 people going.</td>\n",
       "      <td>On the fourth of March, there will be four peo...</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.9864</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I will leave from SFO and want to get back on ...</td>\n",
       "      <td>I'm going to get back from SFO on 7th of march!</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From Vancouver on Monday next week.</td>\n",
       "      <td>On Monday next week, I will be in Vancouver.</td>\n",
       "      <td>some_details_lost</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to continue looking, how about movies d...</td>\n",
       "      <td>i want to keep looking how about movies direct...</td>\n",
       "      <td>some_details_lost</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi, I need a help, i am interested to some thi...</td>\n",
       "      <td>hi i need some help, can you find some games f...</td>\n",
       "      <td>some_details_lost</td>\n",
       "      <td>0.9929</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    INPUT:text_first  \\\n",
       "0                      4th of March, 4 people going.   \n",
       "1  I will leave from SFO and want to get back on ...   \n",
       "2                From Vancouver on Monday next week.   \n",
       "3  I want to continue looking, how about movies d...   \n",
       "4  Hi, I need a help, i am interested to some thi...   \n",
       "\n",
       "                                   INPUT:text_second      OUTPUT:result  \\\n",
       "0  On the fourth of March, there will be four peo...                 OK   \n",
       "1    I'm going to get back from SFO on 7th of march!                 OK   \n",
       "2       On Monday next week, I will be in Vancouver.  some_details_lost   \n",
       "3  i want to keep looking how about movies direct...  some_details_lost   \n",
       "4  hi i need some help, can you find some games f...  some_details_lost   \n",
       "\n",
       "   CONFIDENCE:result  vote_type  vote_different  vote_some_details_lost  \\\n",
       "0             0.9864         12               0                       1   \n",
       "1             0.9999         12               1                       0   \n",
       "2             0.9999         12               0                       2   \n",
       "3             0.9999         12               0                       2   \n",
       "4             0.9929         12               0                       2   \n",
       "\n",
       "   vote_OK   average  \n",
       "0        2  2.666667  \n",
       "1        2  2.333333  \n",
       "2        1  2.333333  \n",
       "3        1  2.333333  \n",
       "4        1  2.333333  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run prepare_metric_inferenceto have all necessary files ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod 755 ./prepare_metric_inference.sh\n",
    "!./prepare_metric_inference.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from all_metrics import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v/fasttext\n",
      "w2v\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51d5b524ac34d8baf6ec9ab79e54abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No exception raised!\n"
     ]
    }
   ],
   "source": [
    "score(df['INPUT:text_first'].tolist(),\n",
    "     df['INPUT:text_second'].tolist(),\n",
    "     df['average'].tolist(),\n",
    "     <SAVE_NAME>,#'SGDD-TST_with_metrics.csv' already has all metrics calculated, you may create a new file if you want to reproduce claculations\n",
    "     calculate_long = False) # set calculate_long to True if you want to get scores from meteor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>human</th>\n",
       "      <th>chrf</th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rouge3</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>Elron/bleurt-large-512</th>\n",
       "      <th>bertscore/roberta-large</th>\n",
       "      <th>bertscore/bert-base-multilingual-cased</th>\n",
       "      <th>bertscore/microsoft/deberta-xlarge-mnli</th>\n",
       "      <th>fasttext_cossim</th>\n",
       "      <th>w2v_cossim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4th of March, 4 people going.</td>\n",
       "      <td>On the fourth of March, there will be four peo...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.453440</td>\n",
       "      <td>0.349133</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.375168</td>\n",
       "      <td>0.938417</td>\n",
       "      <td>0.826329</td>\n",
       "      <td>0.831641</td>\n",
       "      <td>0.756650</td>\n",
       "      <td>0.726442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I will leave from SFO and want to get back on ...</td>\n",
       "      <td>I'm going to get back from SFO on 7th of march!</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.428982</td>\n",
       "      <td>0.546568</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.318186</td>\n",
       "      <td>0.947726</td>\n",
       "      <td>0.863049</td>\n",
       "      <td>0.851195</td>\n",
       "      <td>0.978753</td>\n",
       "      <td>0.871557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From Vancouver on Monday next week.</td>\n",
       "      <td>On Monday next week, I will be in Vancouver.</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.613840</td>\n",
       "      <td>0.596271</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.145527</td>\n",
       "      <td>0.937152</td>\n",
       "      <td>0.816597</td>\n",
       "      <td>0.804163</td>\n",
       "      <td>0.818123</td>\n",
       "      <td>0.901341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to continue looking, how about movies d...</td>\n",
       "      <td>i want to keep looking how about movies direct...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.554911</td>\n",
       "      <td>0.676329</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.378284</td>\n",
       "      <td>0.928749</td>\n",
       "      <td>0.825081</td>\n",
       "      <td>0.915673</td>\n",
       "      <td>0.926830</td>\n",
       "      <td>0.899193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi, I need a help, i am interested to some thi...</td>\n",
       "      <td>hi i need some help, can you find some games f...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.235932</td>\n",
       "      <td>0.179991</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>-0.242777</td>\n",
       "      <td>0.927132</td>\n",
       "      <td>0.822242</td>\n",
       "      <td>0.814345</td>\n",
       "      <td>0.889586</td>\n",
       "      <td>0.852515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0                      4th of March, 4 people going.   \n",
       "1  I will leave from SFO and want to get back on ...   \n",
       "2                From Vancouver on Monday next week.   \n",
       "3  I want to continue looking, how about movies d...   \n",
       "4  Hi, I need a help, i am interested to some thi...   \n",
       "\n",
       "                                               text2     human      chrf  \\\n",
       "0  On the fourth of March, there will be four peo...  2.666667  0.453440   \n",
       "1    I'm going to get back from SFO on 7th of march!  2.333333  0.428982   \n",
       "2       On Monday next week, I will be in Vancouver.  2.333333  0.613840   \n",
       "3  i want to keep looking how about movies direct...  2.333333  0.554911   \n",
       "4  hi i need some help, can you find some games f...  2.333333  0.235932   \n",
       "\n",
       "       bleu    rouge1    rouge2    rouge3    rougeL  Elron/bleurt-large-512  \\\n",
       "0  0.349133  0.352941  0.133333  0.000000  0.352941                0.375168   \n",
       "1  0.546568  0.769231  0.500000  0.272727  0.615385                0.318186   \n",
       "2  0.596271  0.666667  0.461538  0.363636  0.533333                0.145527   \n",
       "3  0.676329  0.846154  0.666667  0.454545  0.846154                0.378284   \n",
       "4  0.179991  0.578947  0.333333  0.176471  0.526316               -0.242777   \n",
       "\n",
       "   bertscore/roberta-large  bertscore/bert-base-multilingual-cased  \\\n",
       "0                 0.938417                                0.826329   \n",
       "1                 0.947726                                0.863049   \n",
       "2                 0.937152                                0.816597   \n",
       "3                 0.928749                                0.825081   \n",
       "4                 0.927132                                0.822242   \n",
       "\n",
       "   bertscore/microsoft/deberta-xlarge-mnli  fasttext_cossim  w2v_cossim  \n",
       "0                                 0.831641         0.756650    0.726442  \n",
       "1                                 0.851195         0.978753    0.871557  \n",
       "2                                 0.804163         0.818123    0.901341  \n",
       "3                                 0.915673         0.926830    0.899193  \n",
       "4                                 0.814345         0.889586    0.852515  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Named Entities based measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from ner_utils import normalize_ner, ner_processor, unfold_list, get_ner_lists_smart_intersection\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32754ed738854ea8a1ef34ee3c31a844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11375e86b16479d9a92686e358879cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent1 = df['text1'].tolist()\n",
    "sent2 = df['text2'].tolist()\n",
    "\n",
    "sent1_ner, sent1_nercount, sent1_noner_count = unfold_list([ner_processor(t, nlp) for t in tqdm(sent1)])\n",
    "sent2_ner, sent2_nercount, sent2_noner_count = unfold_list([ner_processor(t, nlp) for t in tqdm(sent2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4cea63b0cb44598dde174082f76ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = [get_ner_lists_smart_intersection(n1, n2, normalize_ner, substring_search = False) for n1,n2 in zip(tqdm(sent1_ner), sent2_ner)]\n",
    "df['scipy_ner'] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ner_count = [l1+l2 for l1,l2 in zip(sent1_nercount,sent2_nercount)]\n",
    "total_noner_count = [l1+l2 for l1,l2 in zip(sent1_noner_count,sent2_noner_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scipy_proprotion'] = [ner/(ner+noner) for ner,noner in zip(total_ner_count, total_noner_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>human</th>\n",
       "      <th>chrf</th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rouge3</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>Elron/bleurt-large-512</th>\n",
       "      <th>bertscore/roberta-large</th>\n",
       "      <th>bertscore/bert-base-multilingual-cased</th>\n",
       "      <th>bertscore/microsoft/deberta-xlarge-mnli</th>\n",
       "      <th>fasttext_cossim</th>\n",
       "      <th>w2v_cossim</th>\n",
       "      <th>scipy_ner</th>\n",
       "      <th>scipy_proprotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4th of March, 4 people going.</td>\n",
       "      <td>On the fourth of March, there will be four peo...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.453440</td>\n",
       "      <td>0.349133</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.375168</td>\n",
       "      <td>0.938417</td>\n",
       "      <td>0.826329</td>\n",
       "      <td>0.831641</td>\n",
       "      <td>0.756650</td>\n",
       "      <td>0.726442</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I will leave from SFO and want to get back on ...</td>\n",
       "      <td>I'm going to get back from SFO on 7th of march!</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.428982</td>\n",
       "      <td>0.546568</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.318186</td>\n",
       "      <td>0.947726</td>\n",
       "      <td>0.863049</td>\n",
       "      <td>0.851195</td>\n",
       "      <td>0.978753</td>\n",
       "      <td>0.871557</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From Vancouver on Monday next week.</td>\n",
       "      <td>On Monday next week, I will be in Vancouver.</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.613840</td>\n",
       "      <td>0.596271</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.145527</td>\n",
       "      <td>0.937152</td>\n",
       "      <td>0.816597</td>\n",
       "      <td>0.804163</td>\n",
       "      <td>0.818123</td>\n",
       "      <td>0.901341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to continue looking, how about movies d...</td>\n",
       "      <td>i want to keep looking how about movies direct...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.554911</td>\n",
       "      <td>0.676329</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.378284</td>\n",
       "      <td>0.928749</td>\n",
       "      <td>0.825081</td>\n",
       "      <td>0.915673</td>\n",
       "      <td>0.926830</td>\n",
       "      <td>0.899193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi, I need a help, i am interested to some thi...</td>\n",
       "      <td>hi i need some help, can you find some games f...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.235932</td>\n",
       "      <td>0.179991</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>-0.242777</td>\n",
       "      <td>0.927132</td>\n",
       "      <td>0.822242</td>\n",
       "      <td>0.814345</td>\n",
       "      <td>0.889586</td>\n",
       "      <td>0.852515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0                      4th of March, 4 people going.   \n",
       "1  I will leave from SFO and want to get back on ...   \n",
       "2                From Vancouver on Monday next week.   \n",
       "3  I want to continue looking, how about movies d...   \n",
       "4  Hi, I need a help, i am interested to some thi...   \n",
       "\n",
       "                                               text2     human      chrf  \\\n",
       "0  On the fourth of March, there will be four peo...  2.666667  0.453440   \n",
       "1    I'm going to get back from SFO on 7th of march!  2.333333  0.428982   \n",
       "2       On Monday next week, I will be in Vancouver.  2.333333  0.613840   \n",
       "3  i want to keep looking how about movies direct...  2.333333  0.554911   \n",
       "4  hi i need some help, can you find some games f...  2.333333  0.235932   \n",
       "\n",
       "       bleu    rouge1    rouge2    rouge3    rougeL  Elron/bleurt-large-512  \\\n",
       "0  0.349133  0.352941  0.133333  0.000000  0.352941                0.375168   \n",
       "1  0.546568  0.769231  0.500000  0.272727  0.615385                0.318186   \n",
       "2  0.596271  0.666667  0.461538  0.363636  0.533333                0.145527   \n",
       "3  0.676329  0.846154  0.666667  0.454545  0.846154                0.378284   \n",
       "4  0.179991  0.578947  0.333333  0.176471  0.526316               -0.242777   \n",
       "\n",
       "   bertscore/roberta-large  bertscore/bert-base-multilingual-cased  \\\n",
       "0                 0.938417                                0.826329   \n",
       "1                 0.947726                                0.863049   \n",
       "2                 0.937152                                0.816597   \n",
       "3                 0.928749                                0.825081   \n",
       "4                 0.927132                                0.822242   \n",
       "\n",
       "   bertscore/microsoft/deberta-xlarge-mnli  fasttext_cossim  w2v_cossim  \\\n",
       "0                                 0.831641         0.756650    0.726442   \n",
       "1                                 0.851195         0.978753    0.871557   \n",
       "2                                 0.804163         0.818123    0.901341   \n",
       "3                                 0.915673         0.926830    0.899193   \n",
       "4                                 0.814345         0.889586    0.852515   \n",
       "\n",
       "   scipy_ner  scipy_proprotion  \n",
       "0        0.5          0.529412  \n",
       "1        0.5          0.230769  \n",
       "2        1.0          0.600000  \n",
       "3        0.0          0.115385  \n",
       "4        0.0          0.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Named Entities based metric with regular metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "df = pd.read_csv(\"SGDD-TST_with_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrf\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bleu\n",
      "----------------------------------------------------------------------------------------------------\n",
      "rouge1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "rouge2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "rouge3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "rougeL\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Elron/bleurt-large-512\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bertscore/roberta-large\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bertscore/bert-base-multilingual-cased\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bertscore/microsoft/deberta-xlarge-mnli\n",
      "----------------------------------------------------------------------------------------------------\n",
      "fasttext_cossim\n",
      "Dropped 1 null-elements for metric <fasttext_cossim>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "w2v_cossim\n",
      "Dropped 27 null-elements for metric <w2v_cossim>\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "metric_list = []\n",
    "corr_list = []\n",
    "corr_with_total_merge = []\n",
    "ner_columns = ['scipy_proprotion','scipy_ner']\n",
    "\n",
    "ner_dict_list = {'weight_by_scipy_ner':[]}\n",
    "\n",
    "for m in df.columns:\n",
    "    if m not in ['text1','text2','human','scipy_ner','scipy_proprotion']:\n",
    "        print(m)\n",
    "        \n",
    "        dfc = df[['human',m]+ner_columns]\n",
    "        dfc.dropna(inplace = True)\n",
    "        if len(dfc) < len(df):\n",
    "            diff = len(df) - len(dfc)\n",
    "            print(f\"Dropped {diff} null-elements for metric <{m}>\")\n",
    "\n",
    "        human = dfc['human'].tolist()\n",
    "        metric = dfc[m].tolist()\n",
    "   \n",
    "        corr_orig = spearmanr(metric, human).correlation\n",
    "        corr_list.append(corr_orig)\n",
    "        metric_list.append(m)\n",
    "                \n",
    "        dfc[\"merge_by_token_weight_total\"] = dfc.apply(lambda x: x[m]*(1-x['scipy_proprotion']) + \n",
    "                                                                           x['scipy_ner']*(x['scipy_proprotion']), axis = 1)\n",
    "\n",
    "        metric_weighted = dfc[\"merge_by_token_weight_total\"].tolist()\n",
    "\n",
    "        corr_weighted = spearmanr(metric_weighted, human).correlation\n",
    "        ner_dict_list['weight_by_scipy_ner'].append(corr_weighted)\n",
    "        print(\"-\"*100)\n",
    "                \n",
    "df_ner_weighted = pd.DataFrame({'metric':metric_list, \"corr\":corr_list}) \n",
    "for ner_metric, correl_weighted in ner_dict_list.items():\n",
    "    df_ner_weighted[ner_metric] = correl_weighted\n",
    "\n",
    "df_ner_weighted = df_ner_weighted.sort_values(by = 'corr', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>corr</th>\n",
       "      <th>weight_by_scipy_ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Elron/bleurt-large-512</td>\n",
       "      <td>0.561901</td>\n",
       "      <td>0.558323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bertscore/microsoft/deberta-xlarge-mnli</td>\n",
       "      <td>0.465590</td>\n",
       "      <td>0.451859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bertscore/roberta-large</td>\n",
       "      <td>0.397370</td>\n",
       "      <td>0.367713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bleu</td>\n",
       "      <td>0.348286</td>\n",
       "      <td>0.375503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rouge1</td>\n",
       "      <td>0.292041</td>\n",
       "      <td>0.358414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bertscore/bert-base-multilingual-cased</td>\n",
       "      <td>0.284003</td>\n",
       "      <td>0.356662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rougeL</td>\n",
       "      <td>0.271009</td>\n",
       "      <td>0.349383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chrf</td>\n",
       "      <td>0.268488</td>\n",
       "      <td>0.301935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>w2v_cossim</td>\n",
       "      <td>0.216380</td>\n",
       "      <td>0.329118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fasttext_cossim</td>\n",
       "      <td>0.215449</td>\n",
       "      <td>0.323822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rouge2</td>\n",
       "      <td>0.150260</td>\n",
       "      <td>0.219762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rouge3</td>\n",
       "      <td>0.087114</td>\n",
       "      <td>0.138019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     metric      corr  weight_by_scipy_ner\n",
       "6                    Elron/bleurt-large-512  0.561901             0.558323\n",
       "9   bertscore/microsoft/deberta-xlarge-mnli  0.465590             0.451859\n",
       "7                   bertscore/roberta-large  0.397370             0.367713\n",
       "1                                      bleu  0.348286             0.375503\n",
       "2                                    rouge1  0.292041             0.358414\n",
       "8    bertscore/bert-base-multilingual-cased  0.284003             0.356662\n",
       "5                                    rougeL  0.271009             0.349383\n",
       "0                                      chrf  0.268488             0.301935\n",
       "11                               w2v_cossim  0.216380             0.329118\n",
       "10                          fasttext_cossim  0.215449             0.323822\n",
       "3                                    rouge2  0.150260             0.219762\n",
       "4                                    rouge3  0.087114             0.138019"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ner_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check whether the correlation increase is significant with Williams test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def williams_test(r12, r13, r23, n):\n",
    "    \"\"\"The Williams test (Evan J. Williams. 1959. Regression Analysis, volume 14. Wiley, New York, USA)\n",
    "    \n",
    "    A test of whether the population correlation r12 equals the population correlation r13.\n",
    "    Significant: p < 0.05\n",
    "    \n",
    "    Arguments:\n",
    "        r12 (float): correlation between x1, x2\n",
    "        r13 (float): correlation between x1, x3\n",
    "        r23 (float): correlation between x2, x3\n",
    "        n (int): size of the population\n",
    "        \n",
    "    Returns:\n",
    "        t (float): Williams test result\n",
    "        p (float): p-value of t-dist\n",
    "    \"\"\"\n",
    "#     print(\"r12 {}, r13 {} r23 {}\".format(r12, r13, r23))\n",
    "    if r12 < r13:\n",
    "#         print('r12 should be larger than r13')\n",
    "        return 0,0\n",
    "    elif n <= 3:\n",
    "#         print('n should be larger than 3')\n",
    "        return 0,0\n",
    "    else:\n",
    "        K = 1 - r12**2 - r13**2 - r23**2 + 2*r12*r13*r23\n",
    "        denominator = np.sqrt(2*K*(n-1)/(n-3) + (((r12+r13)**2)/4)*((1-r23)**3))\n",
    "        numerator = (r12-r13) * np.sqrt((n-1)*(1+r23))\n",
    "        t = numerator / denominator\n",
    "        p = 1 - stats.t.cdf(t, df=n-3) # changed to n-3 on 30/11/14\n",
    "        return t, p\n",
    "    \n",
    "def decide_if_increase_significant(strong_metric_corr, close2strong_metric_corr, strong_weighted_name, original_strong_name, verbose = False):\n",
    " \n",
    "    r12 = strong_metric_corr \n",
    "    r13 = close2strong_metric_corr\n",
    "    \n",
    "    assert r12>r13\n",
    "    \n",
    "    pair = '_'.join(sorted([strong_weighted_name, original_strong_name]))\n",
    "    r23 = ner_corr_dict[pair]\n",
    "    \n",
    "    n = len(df)\n",
    "\n",
    "    res = williams_test(r12, r13, r23, n)\n",
    "    if res:\n",
    "        pvalue = res[1]\n",
    "        if pvalue < 0.05:\n",
    "            if verbose == True: print(\"Significant Difference! pvalue = {}, stronger_corr = {}, weaker_corr = {}\".format(pvalue, strong_metric_corr, close2strong_metric_corr))\n",
    "            return True\n",
    "        elif pvalue >= 0.05:\n",
    "            if verbose == True: print(\"Not Significant Difference! pvalue = {}, stronger_corr = {}, weaker_corr = {}\".format(pvalue, strong_metric_corr, close2strong_metric_corr))\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "ner_corr_dict = {}\n",
    "for strong_met in df_ner_weighted['metric']:\n",
    "    pair = '_'.join(sorted(['scipy_ner', strong_met]))\n",
    "    if pair not in ner_corr_dict:\n",
    "\n",
    "        df_curr = df[['scipy_ner',strong_met ]]\n",
    "        df_curr.dropna(inplace = True)\n",
    "\n",
    "        m1 = df_curr['scipy_ner']\n",
    "        m2 = df_curr[strong_met]\n",
    "        cr = spearmanr(m1, m2).correlation\n",
    "        ner_corr_dict[pair] = cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elron/bleurt-large-512\n",
      "====================================================================================================\n",
      "bertscore/microsoft/deberta-xlarge-mnli\n",
      "====================================================================================================\n",
      "bertscore/roberta-large\n",
      "====================================================================================================\n",
      "bleu\n",
      "weight_by_scipy_ner\n",
      "Significant Difference! pvalue = 0.005592402489985382, stronger_corr = 0.3755030648225277, weaker_corr = 0.34828591349277077\n",
      "====================================================================================================\n",
      "rouge1\n",
      "weight_by_scipy_ner\n",
      "Significant Difference! pvalue = 1.1451101178394651e-09, stronger_corr = 0.3584137870345997, weaker_corr = 0.29204129744277274\n",
      "====================================================================================================\n",
      "bertscore/bert-base-multilingual-cased\n",
      "weight_by_scipy_ner\n",
      "Significant Difference! pvalue = 8.033329557122215e-11, stronger_corr = 0.35666208621754397, weaker_corr = 0.284003225549297\n",
      "====================================================================================================\n",
      "rougeL\n",
      "weight_by_scipy_ner\n",
      "Significant Difference! pvalue = 3.13915560212763e-12, stronger_corr = 0.3493834509993796, weaker_corr = 0.2710088262057129\n",
      "====================================================================================================\n",
      "chrf\n",
      "weight_by_scipy_ner\n",
      "Significant Difference! pvalue = 0.001236078184662981, stronger_corr = 0.30193533323979793, weaker_corr = 0.26848773502900175\n",
      "====================================================================================================\n",
      "w2v_cossim\n",
      "weight_by_scipy_ner\n",
      "Significant Difference! pvalue = 0.0, stronger_corr = 0.3291179475792798, weaker_corr = 0.21637968477007527\n",
      "====================================================================================================\n",
      "fasttext_cossim\n",
      "weight_by_scipy_ner\n",
      "Significant Difference! pvalue = 0.0, stronger_corr = 0.32382221785104726, weaker_corr = 0.21544894109060303\n",
      "====================================================================================================\n",
      "rouge2\n",
      "weight_by_scipy_ner\n",
      "Significant Difference! pvalue = 1.8034244098075192e-09, stronger_corr = 0.21976154154736455, weaker_corr = 0.1502604507502732\n",
      "====================================================================================================\n",
      "rouge3\n",
      "weight_by_scipy_ner\n",
      "Significant Difference! pvalue = 1.05582442019303e-05, stronger_corr = 0.1380192789808607, weaker_corr = 0.08711401611060927\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "VERBOSE = True\n",
    "signif_dict = {'signif_scipy_ner':[]}\n",
    "\n",
    "df_rep_weighted_moreinfo = df_ner_weighted.copy()\n",
    "\n",
    "for i,el in df_ner_weighted.iterrows():\n",
    "    if VERBOSE == True: print(el['metric'])\n",
    "    close2strong_metric_corr = el['corr']\n",
    "    original_strong_name = el['metric']\n",
    "    for weight_metric in df_rep_weighted_moreinfo.columns[2:]:\n",
    "        strong_weighted_name = re.sub('weight_by_','',weight_metric)\n",
    "        if el[weight_metric] > el['corr']:\n",
    "            if VERBOSE == True: print(weight_metric)\n",
    "            strong_metric_corr = el[weight_metric]\n",
    "            is_significant = decide_if_increase_significant(strong_metric_corr, close2strong_metric_corr, strong_weighted_name, original_strong_name, verbose = VERBOSE)\n",
    "        else: \n",
    "#             is_significant = decide_if_increase_significant(close2strong_metric_corr, strong_metric_corr,original_strong_name, strong_weighted_name, verbose = VERBOSE)\n",
    "#             is_significant = not is_significant\n",
    "             is_significant = False\n",
    "            \n",
    "        signif_dict[f'signif_{strong_weighted_name}'].append(is_significant)\n",
    "    if VERBOSE == True: print(\"=\"*100)\n",
    "#     break\n",
    "    \n",
    "for ner_metric_sign, signif_list in signif_dict.items():\n",
    "    df_rep_weighted_moreinfo[ner_metric_sign] = signif_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hlght(x):\n",
    "    if x['signif_scipy_ner'] == True:\n",
    "        return ['background-color: lightgreen']*len(x)\n",
    "    else:\n",
    "        return ['background-color: white']*len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d7328_row0_col0, #T_d7328_row0_col1, #T_d7328_row0_col2, #T_d7328_row0_col3, #T_d7328_row1_col0, #T_d7328_row1_col1, #T_d7328_row1_col2, #T_d7328_row1_col3, #T_d7328_row2_col0, #T_d7328_row2_col1, #T_d7328_row2_col2, #T_d7328_row2_col3 {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_d7328_row3_col0, #T_d7328_row3_col1, #T_d7328_row3_col2, #T_d7328_row3_col3, #T_d7328_row4_col0, #T_d7328_row4_col1, #T_d7328_row4_col2, #T_d7328_row4_col3, #T_d7328_row5_col0, #T_d7328_row5_col1, #T_d7328_row5_col2, #T_d7328_row5_col3, #T_d7328_row6_col0, #T_d7328_row6_col1, #T_d7328_row6_col2, #T_d7328_row6_col3, #T_d7328_row7_col0, #T_d7328_row7_col1, #T_d7328_row7_col2, #T_d7328_row7_col3, #T_d7328_row8_col0, #T_d7328_row8_col1, #T_d7328_row8_col2, #T_d7328_row8_col3, #T_d7328_row9_col0, #T_d7328_row9_col1, #T_d7328_row9_col2, #T_d7328_row9_col3, #T_d7328_row10_col0, #T_d7328_row10_col1, #T_d7328_row10_col2, #T_d7328_row10_col3, #T_d7328_row11_col0, #T_d7328_row11_col1, #T_d7328_row11_col2, #T_d7328_row11_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d7328_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >metric</th>\n",
       "      <th class=\"col_heading level0 col1\" >corr</th>\n",
       "      <th class=\"col_heading level0 col2\" >weight_by_scipy_ner</th>\n",
       "      <th class=\"col_heading level0 col3\" >signif_scipy_ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d7328_level0_row0\" class=\"row_heading level0 row0\" >6</th>\n",
       "      <td id=\"T_d7328_row0_col0\" class=\"data row0 col0\" >Elron/bleurt-large-512</td>\n",
       "      <td id=\"T_d7328_row0_col1\" class=\"data row0 col1\" >0.561901</td>\n",
       "      <td id=\"T_d7328_row0_col2\" class=\"data row0 col2\" >0.558323</td>\n",
       "      <td id=\"T_d7328_row0_col3\" class=\"data row0 col3\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7328_level0_row1\" class=\"row_heading level0 row1\" >9</th>\n",
       "      <td id=\"T_d7328_row1_col0\" class=\"data row1 col0\" >bertscore/microsoft/deberta-xlarge-mnli</td>\n",
       "      <td id=\"T_d7328_row1_col1\" class=\"data row1 col1\" >0.465590</td>\n",
       "      <td id=\"T_d7328_row1_col2\" class=\"data row1 col2\" >0.451859</td>\n",
       "      <td id=\"T_d7328_row1_col3\" class=\"data row1 col3\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7328_level0_row2\" class=\"row_heading level0 row2\" >7</th>\n",
       "      <td id=\"T_d7328_row2_col0\" class=\"data row2 col0\" >bertscore/roberta-large</td>\n",
       "      <td id=\"T_d7328_row2_col1\" class=\"data row2 col1\" >0.397370</td>\n",
       "      <td id=\"T_d7328_row2_col2\" class=\"data row2 col2\" >0.367713</td>\n",
       "      <td id=\"T_d7328_row2_col3\" class=\"data row2 col3\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7328_level0_row3\" class=\"row_heading level0 row3\" >1</th>\n",
       "      <td id=\"T_d7328_row3_col0\" class=\"data row3 col0\" >bleu</td>\n",
       "      <td id=\"T_d7328_row3_col1\" class=\"data row3 col1\" >0.348286</td>\n",
       "      <td id=\"T_d7328_row3_col2\" class=\"data row3 col2\" >0.375503</td>\n",
       "      <td id=\"T_d7328_row3_col3\" class=\"data row3 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7328_level0_row4\" class=\"row_heading level0 row4\" >2</th>\n",
       "      <td id=\"T_d7328_row4_col0\" class=\"data row4 col0\" >rouge1</td>\n",
       "      <td id=\"T_d7328_row4_col1\" class=\"data row4 col1\" >0.292041</td>\n",
       "      <td id=\"T_d7328_row4_col2\" class=\"data row4 col2\" >0.358414</td>\n",
       "      <td id=\"T_d7328_row4_col3\" class=\"data row4 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7328_level0_row5\" class=\"row_heading level0 row5\" >8</th>\n",
       "      <td id=\"T_d7328_row5_col0\" class=\"data row5 col0\" >bertscore/bert-base-multilingual-cased</td>\n",
       "      <td id=\"T_d7328_row5_col1\" class=\"data row5 col1\" >0.284003</td>\n",
       "      <td id=\"T_d7328_row5_col2\" class=\"data row5 col2\" >0.356662</td>\n",
       "      <td id=\"T_d7328_row5_col3\" class=\"data row5 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7328_level0_row6\" class=\"row_heading level0 row6\" >5</th>\n",
       "      <td id=\"T_d7328_row6_col0\" class=\"data row6 col0\" >rougeL</td>\n",
       "      <td id=\"T_d7328_row6_col1\" class=\"data row6 col1\" >0.271009</td>\n",
       "      <td id=\"T_d7328_row6_col2\" class=\"data row6 col2\" >0.349383</td>\n",
       "      <td id=\"T_d7328_row6_col3\" class=\"data row6 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7328_level0_row7\" class=\"row_heading level0 row7\" >0</th>\n",
       "      <td id=\"T_d7328_row7_col0\" class=\"data row7 col0\" >chrf</td>\n",
       "      <td id=\"T_d7328_row7_col1\" class=\"data row7 col1\" >0.268488</td>\n",
       "      <td id=\"T_d7328_row7_col2\" class=\"data row7 col2\" >0.301935</td>\n",
       "      <td id=\"T_d7328_row7_col3\" class=\"data row7 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7328_level0_row8\" class=\"row_heading level0 row8\" >11</th>\n",
       "      <td id=\"T_d7328_row8_col0\" class=\"data row8 col0\" >w2v_cossim</td>\n",
       "      <td id=\"T_d7328_row8_col1\" class=\"data row8 col1\" >0.216380</td>\n",
       "      <td id=\"T_d7328_row8_col2\" class=\"data row8 col2\" >0.329118</td>\n",
       "      <td id=\"T_d7328_row8_col3\" class=\"data row8 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7328_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_d7328_row9_col0\" class=\"data row9 col0\" >fasttext_cossim</td>\n",
       "      <td id=\"T_d7328_row9_col1\" class=\"data row9 col1\" >0.215449</td>\n",
       "      <td id=\"T_d7328_row9_col2\" class=\"data row9 col2\" >0.323822</td>\n",
       "      <td id=\"T_d7328_row9_col3\" class=\"data row9 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7328_level0_row10\" class=\"row_heading level0 row10\" >3</th>\n",
       "      <td id=\"T_d7328_row10_col0\" class=\"data row10 col0\" >rouge2</td>\n",
       "      <td id=\"T_d7328_row10_col1\" class=\"data row10 col1\" >0.150260</td>\n",
       "      <td id=\"T_d7328_row10_col2\" class=\"data row10 col2\" >0.219762</td>\n",
       "      <td id=\"T_d7328_row10_col3\" class=\"data row10 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7328_level0_row11\" class=\"row_heading level0 row11\" >4</th>\n",
       "      <td id=\"T_d7328_row11_col0\" class=\"data row11 col0\" >rouge3</td>\n",
       "      <td id=\"T_d7328_row11_col1\" class=\"data row11 col1\" >0.087114</td>\n",
       "      <td id=\"T_d7328_row11_col2\" class=\"data row11 col2\" >0.138019</td>\n",
       "      <td id=\"T_d7328_row11_col3\" class=\"data row11 col3\" >True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fce1557f650>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rep_weighted_moreinfo.style.apply(hlght, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_weighted_moreinfo['corr'] = df_rep_weighted_moreinfo['corr'].apply(lambda x: round(x,2))\n",
    "df_rep_weighted_moreinfo['weight_by_scipy_ner'] = df_rep_weighted_moreinfo['weight_by_scipy_ner'].apply(lambda x: round(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>corr</th>\n",
       "      <th>weight_by_scipy_ner</th>\n",
       "      <th>signif_scipy_ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Elron/bleurt-large-512</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bertscore/microsoft/deberta-xlarge-mnli</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bertscore/roberta-large</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.37</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bleu</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.38</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rouge1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bertscore/bert-base-multilingual-cased</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.36</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rougeL</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.35</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chrf</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>w2v_cossim</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.33</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fasttext_cossim</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rouge2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rouge3</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.14</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     metric  corr  weight_by_scipy_ner  \\\n",
       "6                    Elron/bleurt-large-512  0.56                 0.56   \n",
       "9   bertscore/microsoft/deberta-xlarge-mnli  0.47                 0.45   \n",
       "7                   bertscore/roberta-large  0.40                 0.37   \n",
       "1                                      bleu  0.35                 0.38   \n",
       "2                                    rouge1  0.29                 0.36   \n",
       "8    bertscore/bert-base-multilingual-cased  0.28                 0.36   \n",
       "5                                    rougeL  0.27                 0.35   \n",
       "0                                      chrf  0.27                 0.30   \n",
       "11                               w2v_cossim  0.22                 0.33   \n",
       "10                          fasttext_cossim  0.22                 0.32   \n",
       "3                                    rouge2  0.15                 0.22   \n",
       "4                                    rouge3  0.09                 0.14   \n",
       "\n",
       "    signif_scipy_ner  \n",
       "6              False  \n",
       "9              False  \n",
       "7              False  \n",
       "1               True  \n",
       "2               True  \n",
       "8               True  \n",
       "5               True  \n",
       "0               True  \n",
       "11              True  \n",
       "10              True  \n",
       "3               True  \n",
       "4               True  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rep_weighted_moreinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_weighted_moreinfo.to_csv(\"t.tsv\", index = None, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used numerous content similarity measures as is, and we used a Named Entities-based measure as an auxiliary signal. In the table above we have shown that for most standard measures (like BLEU or rouge) and even for some more sophisticated ones (e.g. based on word2vec) this approach yields siginifcant improvement in correlation with human judgements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
